{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2227d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert dataset and look first row of data\n",
    "df = pd.read_csv(r'C:\\Users\\govind\\Desktop\\sample test\\winequality-red.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0807bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many features are there, which are they\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cf2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the first 5 rows of features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Along with the feature Let's check NULL Values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the data types of features\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can observe that the \"Total Charges\" column has continuous data but it is an object type. Let us handle this column\n",
    "\n",
    "df['quality'].unique() # we see there is object data in the int data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0dfe3f",
   "metadata": {},
   "source": [
    "For Classification model :- we will make the target variable into binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'] = np.where(df['quality']>5,1,df['quality'])\n",
    "df['quality'] = np.where(df['quality']!=1,0,df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb249aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a70c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the total no. of variables in target variable\n",
    "df['quality'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b29ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ab5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e38f2c1",
   "metadata": {},
   "source": [
    " ## From the above dataframe, We see how the target variable converted into binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b24191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b04808f",
   "metadata": {},
   "source": [
    "#we have again no nulls so we can move on\n",
    "\n",
    "#Now we can see that the Total Charges column has been converted to float type , Now we can handle the null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b16499b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a562ad5c",
   "metadata": {},
   "source": [
    "> We notice all values are accounted for\n",
    "\n",
    "> The mean and std of each coloumn are fairly good\n",
    "\n",
    "> We also seem to have some extreme values in free sulphur dioxide as well as total sulfer dioxide\n",
    "\n",
    "> We have no outlier in most cases and no data reduntantcy, so moving to visualizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32beb6e4",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15),facecolor='yellow')\n",
    "plotnumber=1\n",
    "\n",
    "for column in df:\n",
    "    if plotnumber <=12:\n",
    "        ax = plt.subplot(3,4,plotnumber)\n",
    "        sns.distplot(df[column])\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        \n",
    "    plotnumber +=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7e98d",
   "metadata": {},
   "source": [
    "We see some skewness so we will use boxplot to get more idea\n",
    "\n",
    "OUTliers Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ffdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,25))\n",
    "graph=1\n",
    "\n",
    "for column in df:\n",
    "    if graph <=12:\n",
    "        ax=plt.subplot(3,4,graph)\n",
    "        sns.boxplot(data = df[column])\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        \n",
    "    graph +=1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1283aa9",
   "metadata": {},
   "source": [
    "### As we see there are lots of outliers both lower and upper ends, but outliers cannot be remove because of small dataset we have.So we will procceed with the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see how the data is distributed for every column as a whole\n",
    "\n",
    "#Divide data into features and label\n",
    "\n",
    "y = df['quality']\n",
    "X = df.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08711a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing Relationship\n",
    "\n",
    "plt.figure(figsize =(15,10), facecolor = 'yellow')\n",
    "plotnumber = 1\n",
    "\n",
    "for column in X:\n",
    "    if plotnumber <=12:\n",
    "        ax = plt.subplot(3,4,plotnumber)\n",
    "        plt.scatter(X[column],y)\n",
    "        plt.xlabel(column,fontsize = 20)\n",
    "        plt.ylabel('quality',fontsize = 10)\n",
    "    plotnumber +=1\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410e388",
   "metadata": {},
   "source": [
    "USING CORRELATION AND HEAT MAP TO FURTHER STUDY RELATIONSHIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['quality'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd562ff",
   "metadata": {},
   "source": [
    "#we dont see too much variation in the feature-target relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647264fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,7))\n",
    "sns.heatmap(df.corr(),annot=True,linewidths=0.1,linecolor=\"black\",fmt='0.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81250a",
   "metadata": {},
   "source": [
    "#Considering the outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92349409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "z=np.abs(zscore(df))\n",
    "threshold=3\n",
    "np.where(z>3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65996b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z=df[(z<3).all(axis=1)]\n",
    "df_new_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ec4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loss Calculation\n",
    "data_loss = ((1599-1458)/1599)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72955436",
   "metadata": {},
   "source": [
    "## Seperating the Columns into Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_new_z.drop(['quality'],axis=1)\n",
    "y=df_new_z['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216a117",
   "metadata": {},
   "source": [
    "Scaling the data using Standard Scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve,roc_auc_score, classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lr = LogisticRegression()\n",
    "scaled = StandardScaler()\n",
    "\n",
    "X_scaler = scaled.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a788b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaler,y,test_size = 0.25, random_state = 355)\n",
    "lr.fit(X_train,y_train)\n",
    "pred_train = lr.predict(X_train)\n",
    "pred_test=lr.predict(X_test)\n",
    "\n",
    "print(f\"At random state, the training accuracy is :-{r2_score(y_train,pred_train)}\")\n",
    "print(f\"At random state, the training accuracy is :-{r2_score(y_test,pred_test)}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X_scaler,y,test_size = 0.25,random_state = 355) #the model is having too less accracy scores so we try another method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write one function and call as many times to check accuracy_score of different models\n",
    "\n",
    "def metric_score(clf,X_train,X_test,y_train,y_test,train=True):\n",
    "    if train:\n",
    "        y_pred = clf.predict(X_train)\n",
    "        \n",
    "        print(\"\\n===============================Train Result=============================\")\n",
    "        \n",
    "        print(f\"Accuracy score : {accuracy_score(y_train,y_pred) * 100: .2f}%\")\n",
    "        \n",
    "    elif train == False:\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        print(\"\\n===============================Test Result===============================\")\n",
    "        print(f\"Accuracy Scorre : {accuracy_score(y_test,pred) * 100: .2f}%\")\n",
    "        \n",
    "        \n",
    "        print ('\\n \\n Test Classification Report \\n', classification_report(y_test, pred, digits = 2)) ##Model Confidence /Accurancy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(lr,X_train,X_test,y_train,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(lr,X_train,X_test,y_train,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ecb1b3",
   "metadata": {},
   "source": [
    "### We are getting very less accuracy with Logisticregression so lets use other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ae237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2eb1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "rf=RandomForestClassifier()\n",
    "kn=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with all classifiers\n",
    "rf.fit(X_train,y_train)\n",
    "kn.fit(X_train,y_train)\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "print(\"All models are Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All models score captured\n",
    "dt.score(X_test,y_test)\n",
    "kn.score(X_test,y_test)\n",
    "rf.score(X_test,y_test)\n",
    "\n",
    "print (\"All models test score are captured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function and pass dataset to check the train score and the test score\n",
    "\n",
    "metric_score(dt,X_train,X_test,y_train,y_test,train=True) #This is for the Training Score\n",
    "\n",
    "metric_score(dt,X_train,X_test,y_train,y_test,train=False) #This is for the Testing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e40a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "metric_score(rf,X_train,X_test,y_train,y_test,train=True)\n",
    "\n",
    "metric_score(rf,X_train,X_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d872476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc =SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "metric_score(svc,X_train,X_test,y_train,y_test,train=True)\n",
    "\n",
    "metric_score(svc,X_train,X_test,y_train,y_test,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a3837",
   "metadata": {},
   "source": [
    "As above scores SVC score is practically less than other algorithm, so we can assume that Random Forest Classifier is the best Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0512b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate KNeighbourClassifier\n",
    "knn  = KNeighborsClassifier()\n",
    "#model training\n",
    "knn.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5679aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function and pass the dataset to check train and test score)\n",
    "metric_score(knn,X_train,X_test,y_train,y_test,train=True) # This is for training score\n",
    "metric_score(knn,X_train,X_test,y_train,y_test,train=False) # This is for testing score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "k_f = KFold(n_splits = 5, random_state=None, shuffle=True)\n",
    "k_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511afe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train,test in k_f.split([1,2,3,4,5,6,7,8,9,10]):\n",
    "    print('train:',train, 'test:',test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation score to check if the modle is overfitting\n",
    "\n",
    "cross_val_score(knn,X_scaler,y,cv=7).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070f4840",
   "metadata": {},
   "source": [
    "Here we have handles the problem of the overfitting and the underfitting by chceking the training and testing score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b711b",
   "metadata": {},
   "source": [
    "Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating parameter to pass in GridSearchCV\n",
    "\n",
    "\n",
    "parameters = {'max_features' :['auto','sqrt','log2'],\n",
    "             'max_depth' :[4,5,6,7,8],\n",
    "              'criterion' : ['gini', 'entropy'],\n",
    "              'n_estimators' : [100,200,300,400,500]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b12573",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV = GridSearchCV(estimator =rf,param_grid=parameters,cv=7,scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.fit(x_train,y_train) #fitting data into the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV.best_params_ #printing the best parameters found by the GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9df6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCV_pred = GVC.best_estimator_.predict(x_test) # predicting with the best parameter\n",
    "accuracy_score(y_test,GCV_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523c63a",
   "metadata": {},
   "source": [
    "We are getting model Accuracy and cross-validation both as 82.4% which shows our model is performing moderately well and better that the earlier score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9527f99",
   "metadata": {},
   "source": [
    "### ROC AUC Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "plot_roc_curve(GCV.best_estimator_,x_test,y_test)\n",
    "plt.title(\"ROC AUC Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename ='Wine.pkl'\n",
    "pikle.dump(GCD,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbdbf7e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22e7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('Wine.pkl','rb'))\n",
    "result = loaded_model.score(x_test,y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7bdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion = pd.DataFrame([loaded_model.predict(x_test)[:],GCV_pred[:]],index=['predicted','Original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15266da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bf0779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f0956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb51ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bec94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9906c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db74eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a9662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d56f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3932dca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa81a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36948fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f8108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fcad6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
